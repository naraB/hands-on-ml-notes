{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "lkDgPLge9BoU",
        "er-Ye_SGARtB",
        "uuSkU6SgBco_",
        "9NJ3oSnYEUNo",
        "8rLYeeJqIAkA"
      ],
      "authorship_tag": "ABX9TyNmLMsCnfA2pUI6QFU604Pt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naraB/handson-ml-notes/blob/master/classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYR0aG7W1rsy",
        "colab_type": "text"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPCy7XMxAMhg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkDgPLge9BoU",
        "colab_type": "text"
      },
      "source": [
        "## Downloading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sChauhkH9SOS",
        "colab_type": "code",
        "outputId": "983e93c9-409e-4b46-d956-a0ed823cf713",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml('mnist_784', version=1)\n",
        "mnist.keys()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'DESCR', 'details', 'categories', 'url'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UT_u_YBF9le2",
        "colab_type": "text"
      },
      "source": [
        "Datasets loaded by Scikit-Learn generally have a similar dictionary structure: \n",
        "\n",
        "* *DESCR* key describing the dataset\n",
        "* *data* key containing an array with one row per instance and one column per feature\n",
        "* *target* key containing an array with labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fs2JMtJk9729",
        "colab_type": "code",
        "outputId": "7fccdb25-18eb-4fb9-eaba-5a0f79806341",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X,y = mnist['data'], mnist['target']\n",
        "print('X shape', X.shape)\n",
        "print('y shape', y.shape)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X shape (70000, 784)\n",
            "y shape (70000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvWFx80q-L5s",
        "colab_type": "text"
      },
      "source": [
        "There are 70,000 images, and each image has 784 features. This is because each image is 28 * 28 pixels, and each feature simply represents one pixel's instensity, from 0 (white) to 255 (black). Lets take apeek at one digit from the dataset. All we need to do is grab an instance's feature vector, reshapre it to a 28 * 28 array, and display it using Matplotlib's imhsow() function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2PoIlda_Nhh",
        "colab_type": "code",
        "outputId": "9218f422-a42b-4b39-89ca-2f3c29e2c288",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "some_digit = X[0]\n",
        "print(some_digit.shape)\n",
        "some_digit_image = some_digit.reshape(28, 28)\n",
        "plt.imshow(some_digit_image, cmap=\"binary\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(784,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAGaElEQVR4nO3dPUiWfR/G8dveSyprs2gOXHqhcAh6\nhZqsNRqiJoPKRYnAoTGorWyLpqhFcmgpEmqIIByKXiAHIaKhFrGghiJ81ucBr991Z/Z4XPr5jB6c\nXSfVtxP6c2rb9PT0P0CeJfN9A8DMxAmhxAmhxAmhxAmhljXZ/Vcu/H1tM33RkxNCiRNCiRNCiRNC\niRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNC\niRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCLZvvG+B//fr1q9y/\nfPnyVz9/aGio4fb9+/fy2vHx8XK/ceNGuQ8MDDTc7t69W167atWqcr948WK5X7p0qdzngycnhBIn\nhBInhBInhBInhBInhBInhHLOOYMPHz6U+48fP8r92bNn5f706dOG29TUVHnt8PBwuc+nLVu2lPv5\n8+fLfWRkpOG2du3a8tpt27aV+759+8o9kScnhBInhBInhBInhBInhBInhGqbnp6u9nJsVS9evCj3\ngwcPlvvffm0r1dKlS8v91q1b5d7e3j7rz960aVO5b9iwody3bt0668/+P2ib6YuenBBKnBBKnBBK\nnBBKnBBKnBBKnBBqUZ5zTk5Olnt3d3e5T0xMzOXtzKlm997sPPDx48cNtxUrVpTXLtbz3zngnBNa\niTghlDghlDghlDghlDghlDgh1KL81pgbN24s96tXr5b7/fv3y33Hjh3l3tfXV+6V7du3l/vo6Gi5\nN3un8s2bNw23a9euldcytzw5IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IdSifJ/zT339+rXcm/24ut7e3obb\nzZs3y2tv375d7idOnCh3InmfE1qJOCGUOCGUOCGUOCGUOCGUOCHUonyf80+tW7fuj65fv379rK9t\ndg56/Pjxcl+yxL/HrcKfFIQSJ4QSJ4QSJ4QSJ4QSJ4Tyytg8+PbtW8Otp6envPbJkyfl/uDBg3I/\nfPhwuTMvvDIGrUScEEqcEEqcEEqcEEqcEEqcEMo5Z5iJiYly37lzZ7l3dHSU+4EDB8p9165dDbez\nZ8+W17a1zXhcR3POOaGViBNCiRNCiRNCiRNCiRNCiRNCOedsMSMjI+V++vTpcm/24wsrly9fLveT\nJ0+We2dn56w/e4FzzgmtRJwQSpwQSpwQSpwQSpwQSpwQyjnnAvP69ety7+/vL/fR0dFZf/aZM2fK\nfXBwsNw3b948689ucc45oZWIE0KJE0KJE0KJE0KJE0KJE0I551xkpqamyv3+/fsNt1OnTpXXNvm7\n9M+hQ4fK/dGjR+W+gDnnhFYiTgglTgglTgglTgglTgjlKIV/beXKleX+8+fPcl++fHm5P3z4sOG2\nf//+8toW5ygFWok4IZQ4IZQ4IZQ4IZQ4IZQ4IdSy+b4B5tarV6/KfXh4uNzHxsYabs3OMZvp6uoq\n97179/7Rr7/QeHJCKHFCKHFCKHFCKHFCKHFCKHFCKOecYcbHx8v9+vXr5X7v3r1y//Tp02/f07+1\nbFn916mzs7PclyzxrPhvfjcglDghlDghlDghlDghlDghlDghlHPOv6DZWeKdO3cabkNDQ+W179+/\nn80tzYndu3eX++DgYLkfPXp0Lm9nwfPkhFDihFDihFDihFDihFDihFCOUmbw+fPncn/79m25nzt3\nrtzfvXv32/c0V7q7u8v9woULDbdjx46V13rla2753YRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQC/acc3Jy\nsuHW29tbXvvy5ctyn5iYmNU9zYU9e/aUe39/f7kfOXKk3FevXv3b98Tf4ckJocQJocQJocQJocQJ\nocQJocQJoWLPOZ8/f17uV65cKfexsbGG28ePH2d1T3NlzZo1Dbe+vr7y2mbffrK9vX1W90QeT04I\nJU4IJU4IJU4IJU4IJU4IJU4IFXvOOTIy8kf7n+jq6ir3np6ecl+6dGm5DwwMNNw6OjrKa1k8PDkh\nlDghlDghlDghlDghlDghlDghVNv09HS1lyMwJ9pm+qInJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QS\nJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4Rq9iMAZ/yWfcDf58kJocQJ\nocQJocQJocQJocQJof4DO14Dhyk10VwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTEVu5sh_30r",
        "colab_type": "code",
        "outputId": "f3da5345-b4f2-4599-92fa-9c86531fa81d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y[0]"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwFfbB4A_7xc",
        "colab_type": "text"
      },
      "source": [
        "Note that the label is a string. Most ML algorithms expect numbers, so lets cast y to integer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4x9hmS1mABfM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = y.astype(np.uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "er-Ye_SGARtB",
        "colab_type": "text"
      },
      "source": [
        "## Creating test and train set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-o54XC5EAVh4",
        "colab_type": "text"
      },
      "source": [
        "The MNIST dataset is already split into a training set (the first 60,000 images) and test set (the last 10,000 images)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_l8gMcJaAfEF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LiYqk_3AtBQ",
        "colab_type": "text"
      },
      "source": [
        "The training data is already shuffled for us"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFgyoDBBA3KW",
        "colab_type": "text"
      },
      "source": [
        "## Binary Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA0Km9muBiB-",
        "colab_type": "text"
      },
      "source": [
        "Let's simplify the problem for now and only tr to identify one digit - for example, te number 5. This \"5-detector\" will be an example of a binary classifier, capable of distinguishing between just two classes, 5 and not-5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVBzanVGByzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_5 = (y_train == 5)\n",
        "y_test_5 = (y_test == 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuSkU6SgBco_",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuVASG1HB33D",
        "colab_type": "text"
      },
      "source": [
        "Let's use a *Stochastic Gradient Descent* (SGD) classifier, Scikit-learn's SGDClassifier class.\n",
        "\n",
        "The classifier has the advantage of being capable of handling very large datasets efficiently. This is in part because SGD deals with training instances independently, one at a time (which also makes SGD well suited for online learning), as we will see later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcK_jNO-Clii",
        "colab_type": "code",
        "outputId": "7e2b728e-c242-458f-e832-9934ecda1f6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "sgd_clf = SGDClassifier(random_state=42)\n",
        "sgd_clf.fit(X_train, y_train_5)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
              "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
              "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
              "              power_t=0.5, random_state=42, shuffle=True, tol=0.001,\n",
              "              validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XDnVDrrC5Vw",
        "colab_type": "text"
      },
      "source": [
        "Now we can use it to detect images of the number 5:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy4JKcDmD1lX",
        "colab_type": "code",
        "outputId": "dacbce54-6350-455f-f907-c8f7a4f1fa9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sgd_clf.predict([some_digit])"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpG0u5zcD_B8",
        "colab_type": "text"
      },
      "source": [
        "### Performance Measures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNm9IpZ-ED37",
        "colab_type": "text"
      },
      "source": [
        "Evaluating a classifier is often significantly trickier than evaluating a regressor, so we will spend a large part of this chapter on this topic. There are many performance measures available."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NJ3oSnYEUNo",
        "colab_type": "text"
      },
      "source": [
        "#### Measuring Accuracy Using Cross-Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gSRtkseEdGY",
        "colab_type": "text"
      },
      "source": [
        "A good way to evaluate a model is to use cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGHNQQ5DEhb4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4ffe963e-a247-40f4-c64b-1b5b420ee69d"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.95035, 0.96035, 0.9604 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wle-xs31Hzqq",
        "colab_type": "text"
      },
      "source": [
        "Accuracy is generally not the preferred performance measure for classifiers, especially when you are dealing with skewed datasets (i.e., when some classes are much more frequent than others)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rLYeeJqIAkA",
        "colab_type": "text"
      },
      "source": [
        "#### Confusion Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efxC3Q1jIEJI",
        "colab_type": "text"
      },
      "source": [
        "A much better way to evaluate the performance of a classifier is to look at the confusion matrix. The general idea is to count the number of times instances of class A are classified as class B. For example, to know the number of times the classifier confused images of 5s with 3s, you would look in the fifth row and third column of the confusion matrix.\n",
        "\n",
        "To compute the confusion matrix, we first need to have a set of predictions so that they can be compared to the actual targets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzyvqnQcIlQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ly18o9gJugg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ce74f99c-1546-4d7d-9b4a-0d5d1bd7a8bc"
      },
      "source": [
        "y_train_pred"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True, False, False, ...,  True, False, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnizqzDgI-3W",
        "colab_type": "text"
      },
      "source": [
        "Just like the cross_val_score() function, cross_val_predict() performs K-fold cross-validation, but instead of returning the evaluation scores, it returns the predictions made on each test fold. This means that you get a clean prediction for each instance in the training set (\"clean\" meaning that the prediction is made by a model that never saw the data during training)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqaKkpbSNhCV",
        "colab_type": "text"
      },
      "source": [
        "cross_val_predict() splits the data into K parts (as does cross_val_score()) and then for i=1...k iterations: \n",
        "\n",
        "* takes the i-th part as test data and all other parts as training data\n",
        "\n",
        "* trains the model with training data (all parts except i-th part)\n",
        "\n",
        "* then by using this trained model, predicts labels for i-th part (test data)\n",
        "\n",
        "In each iteration, label of i-th part of the data gets predicted. In the end cross_val_prediction concatenates all partially predicted labels and returns them as the final result.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CesXRvejJUHS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "99b62075-1263-488c-ef3c-37fc7e59d096"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_train_5, y_train_pred)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[53892,   687],\n",
              "       [ 1891,  3530]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NbDNx0aO2yK",
        "colab_type": "text"
      },
      "source": [
        "Each row in a confusion matrix represents an actual class, while each column represents a predicted class. The first row of this matrix considers non-5 images (*negative class*): 53,892 of them were correctly classified as non-5s (they are called *true negatives*), while the remaining 687 were wrongly classified as 5s (*false positives*). The second row considers the images of 5s (*positive class*): 1,891 were wrongly classified as non-5s (*false negatives*), while the ramaining 3,530 were correctly classified as 5s (*true positives*). \n",
        "\n",
        "To recap:\n",
        "\n",
        "* *negative class*: first row (non-5 images)\n",
        "* *postive class*: second row (images of 5s)\n",
        "* *true negatives*: correctly classified as non 5's (52,892)\n",
        "* *true postives*: correctly classified as 5's (3,530)\n",
        "* *false postives*: wrongly classified as 5's (687)\n",
        "* *false negatives*: wrongly classified as non 5's (1,891)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1-V7SStOBv1",
        "colab_type": "text"
      },
      "source": [
        "A perfect classifier would have only true positives and true negatives, so its confusion matrix would have nonzero values only on its main diagonal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dj_tBtSjNv7U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e5931de3-293a-4f4c-ff17-ef9a7d69f5da"
      },
      "source": [
        "y_train_perfect_predictions = y_train_5\n",
        "confusion_matrix(y_train_5, y_train_perfect_predictions)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[54579,     0],\n",
              "       [    0,  5421]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GHu3KHzOR6I",
        "colab_type": "text"
      },
      "source": [
        "#### Precision and Recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XROMqPTOaTM",
        "colab_type": "text"
      },
      "source": [
        "**Precision = the accuracy of the positive predictions; the precision of the classifier**\n",
        "\n",
        "* precision = TP / (TP + FP)\n",
        "\n",
        "* TP = number of true positives\n",
        "* FP = number of false positives\n",
        "\n",
        "* What is the ratio of correctly classified 5's and wrongly classified 5's (false positives) + correctly classified 5's\n",
        "\n",
        "* What percentage are the actual correctly predicted 5's out of all predicted 5's\n",
        "\n",
        "* How precise was my positive predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TI5ob8DkO312",
        "colab_type": "text"
      },
      "source": [
        "***Recall* (also *sensitivity* or the *true positive rate*) = the ratio of positives instances that are correctly detected by the classifier**\n",
        "\n",
        "* recall = TP / (TP + FN)\n",
        "\n",
        "* FN = false negatives\n",
        "\n",
        "* What is the ratio of correctly classified 5's and missed 5's (wrongly classified non-5's) + correctly classified 5's\n",
        "\n",
        "* Ratio of how many out of all of the positive class we classified correctly\n",
        "\n",
        "* How many actual positives did I miss?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPptrLCEU3zC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3e49021-f04a-4710-9a61-7fba09ec5dea"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "precision_score(y_train_5, y_train_pred)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8370879772350012"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxxAjvkhVDRa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0040eb4d-ea3f-47f9-e8b0-2472187f3bd1"
      },
      "source": [
        "recall_score(y_train_5, y_train_pred)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6511713705958311"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMzVTZawVQdq",
        "colab_type": "text"
      },
      "source": [
        "Precision\n",
        "* Wrongly classified approx. 17% non 5's as 5's\n",
        "* When it claims an image represents a 5, it's correct 83% of the time\n",
        "\n",
        "\n",
        "Recall\n",
        "* Wrongly classified approx 35% as non 5's even though they were 5's\n",
        "* Detects 65% of all of the 5's\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3ImGWGjc9ZG",
        "colab_type": "text"
      },
      "source": [
        "##### F1 Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGKvmSMxdAAM",
        "colab_type": "text"
      },
      "source": [
        "F1 score = combines precision and recall into a single metric and is a simple way to compare two classifiers\n",
        "\n",
        "The F1 score is the harmonic mean of precision and recall. Whereas the regular mean trats all values equally, the harmonic mean gives much more weight to low values. As aresult, the classifier will only get a high F1 score if both recall and precision are high."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFyAB6Ude_F-",
        "colab_type": "text"
      },
      "source": [
        "F1 = 2 * (precision * recall) / (precision + recall)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbxVW6hTdsWd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "59a41ac0-736f-46ab-a362-2bf4061635fd"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score(y_train_5, y_train_pred)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7325171197343846"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r62CLR6S901I",
        "colab_type": "text"
      },
      "source": [
        "The F1 score favors classifiers that have similiar precision and recall. This is not always what you want: in some contexts you mostly care about precision, and in other contexts you really care about recall. For example, if you trained a classifier to detect videos that are safe for kids, you would probably prefer a classifier that rejects many good videos (low recall) but keeps only safe ones (high precision). On the other hand, suppose you train a classifier to detect shoplifters in surveillance images: it is probably fine if your classifier has only 30% precision as long as it has 99% recall\n",
        "\n",
        "Unfortunately, you can't have it both ways: increasing precision reduces recall, and vice versa. This is called the *precision/recall trade-off*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fklQcaK1_LHP",
        "colab_type": "text"
      },
      "source": [
        "##### Precision/Recall Trade-off"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aInfqy6J_OLf",
        "colab_type": "text"
      },
      "source": [
        "To understand this trade-off, let's look at how the SGDClassifier makes its classification decisions. For each instance, it computes a score based on a decision function. If that score is greater than a threshold, it assigns the instance to the positive class; otherwise it assigns it to the negative class. Conversly, lowering the threshold increases recall and reduces precision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEObX2saA2sC",
        "colab_type": "text"
      },
      "source": [
        "Scikit-Learn does not let you set the threshold directly, but it does give you access to the decision scores that it uses to make predictions. Instead of calling the classifier's predict() method, you can call its decision_function() method, which returns a score for each instance, and then use any threshold you want to make predictions base on those scores:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwntsafjBGjZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d422813c-1d4a-47e3-a3af-9204cc044988"
      },
      "source": [
        "y_scores = sgd_clf.decision_function([some_digit])\n",
        "y_scores"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2164.22030239])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjfMWV8CBLE3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5222577c-df90-4f7b-d32d-36e2d176e6b6"
      },
      "source": [
        "threshold = 0\n",
        "y_some_digit_pred = (y_scores > threshold)\n",
        "y_some_digit_pred"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xq9yiOBoBoXM",
        "colab_type": "text"
      },
      "source": [
        "How do you decide which threshold to use? \n",
        "* First, use the cross_val_predict() function to get the scores of all instances in the training set, but this time specify that you want to return decision scores instead of predictions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJaplEdUB2xF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3,\n",
        "                             method=\"decision_function\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leRPxyFCCEYZ",
        "colab_type": "text"
      },
      "source": [
        "With these scores, use the precision_recall_curve() function to compute precision and recall for all possible thresholds:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXDn8BBdCLEF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YCmOD3tCTMo",
        "colab_type": "text"
      },
      "source": [
        "Finally, use Matplotlib to plot precision and recall as functions of the threshold value:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DKKzVgOCcwK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# highlight the threshold and add the legend, axis label, and grid\n",
        "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
        "  plt.plot(thresholds, precisions[:-1], 'b--', label='Precision')\n",
        "  plt.plot(thresholds, recalls[:-1], 'g-', label='Recall')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqC72KjRCsjs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "f7370c2e-a79e-4b8a-bc92-cd01b59e6ad2"
      },
      "source": [
        "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
        "plt.show()"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndKWUihCa0JVSKkJoQldKqQjx/wGeZhtL1wreDgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiXqL_hCDbVE",
        "colab_type": "text"
      },
      "source": [
        "Another way to select a good precision/recall trade-off is to plot precision directly against recall:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7aB77lwDinG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "feb86e1d-8369-4759-d6aa-3b318ab6b74d"
      },
      "source": [
        "thresholds_90_precision = thresholds[np.argmax(precisions >= 0.90)]\n",
        "thresholds_90_precision"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3370.0194991439557"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7liWxk4nETcb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_pred_90 = (y_scores >= thresholds_90_precision)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN7E3CslEacL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ea692e40-9ac0-4d1c-9686-fd1eda414792"
      },
      "source": [
        "precision_score(y_train_5, y_train_pred_90)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9000345901072293"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpt3DbumEdjy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "64155979-77a0-4f0b-d578-96e15a86d124"
      },
      "source": [
        "recall_score(y_train_5, y_train_pred_90)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4799852425751706"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    }
  ]
}